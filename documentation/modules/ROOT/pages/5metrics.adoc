= Tailor metrics

When building distributed systems, you should use metrics to ensure that you see all your requests, including errors or slow requests etc.
Tracing helps you with following the evolution of a transaction and it usually needs to be sampled at high volumes of traffic
(because the amount of data increases proportionally to the traffic volume).

== Setup

To get the application, clone this repository and go to `apps/another-greeting-app`.

[.console-input]
[source,bash]
----
git clone https://github.com/redhat-scholars/kubernetes-apps-resource-management.git

cd apps/another-greeting-app
----

[tabs]
====
Developer Sandbox::
+
--
As we will need to correlate our metrics and traces, we should make a setup for Prometheus.

IMPORTANT: This setup has development purposes and is due to resource constraints that exist within Red Hat OpenShift Developer Sandbox.

First, open the Web Terminal of your Sandbox and type the command:
[.console-input]
[source,bash]
----
curl -O "https://raw.githubusercontent.com/redhat-scholars/kubernetes-apps-respource-management/master/apps/kubefiles/{prometheus-configmap.yaml,prometheus-deployment.yaml}"
----

This will download the files used to configure Jaeger/Prometheus/OpenTelemetry collector.

Next, please run the following commands in the same terminal:

[.console-input]
[source,bash]
----
kubectl apply -f prometheus-configmap.yaml
oc new-app --docker-image=quay.io/prometheus/prometheus:latest
kubectl replace -f prometheus-deployment.yaml
oc expose svc prometheus
----
--
====

[#metricsquarkus]
== Metrics in Quarkus

Firstly, let's add the micrometer extension to our setup.
In the terminal window run:

[tabs]
====
Mac::
+
--
[.console-input]
[source,bash]
----
./mvnw quarkus:add-extension -Dextensions="io.quarkus:quarkus-micrometer-registry-prometheus"
----
--
Windows::
+
--
[.console-input]
[source,bash]
----
mvnw.cmd quarkus:add-extension -Dextensions="io.quarkus:quarkus-micrometer-registry-prometheus"
----
--
====

=== Configuration of common tags

When deploying accross multiple projects/namespaces is always good to have an unified view over some application metrics.
Let's define several common tags for the application, varying in value at deployment time:

[.console-input]
[source,java]
----
package com.redhat.developers;

import io.smallrye.config.ConfigMapping;

@ConfigMapping(prefix = "global")
interface GlobalTagsConfig {
     String PROFILE = "profile";
     String REGION = "region";
     String COUNTRY="country";

     String region();
     String country();
}
----

`@ConfigMapping(prefix = "global")` annotation maps configurations from `application.properties` prefixed by `global`:

[.console-input]
[source,properties]
----
global.region=${REGION:CEE} <1>
global.country=${COUNTRY:Romania}
----

<1> Environment configuration will be named `REGION` and having the default value `CEE`.

Further, we will propagate these configurations by via `MeterFilter` customization:

[.console-input]
[source,java]
----
package com.redhat.developers;

import io.micrometer.core.instrument.Tag;
import io.micrometer.core.instrument.config.MeterFilter;
import io.quarkus.runtime.configuration.ProfileManager;

import javax.enterprise.inject.Produces;
import javax.inject.Inject;
import javax.inject.Singleton;
import java.util.Arrays;

@Singleton
public class CustomConfiguration {

    @Inject
    GlobalTagsConfig tagsConfig;

    @Produces
    @Singleton
    public MeterFilter configureTagsForAll() {
        return MeterFilter.commonTags(Arrays.asList(
           Tag.of(GlobalTagsConfig.REGION, tagsConfig.region()),
           Tag.of(GlobalTagsConfig.COUNTRY, tagsConfig.country()),
           Tag.of(GlobalTagsConfig.PROFILE, ProfileManager.getActiveProfile())
        ));
    }

}
----

=== Metrics definition at endpoint level

When looking to improve the performance of certain application features, is useful to have metrics defined at endpoint level as well.


In `application.properties` please add the following configurations:

[.console-input]
[source,properties]
----
quarkus.micrometer.binder.http-client.enabled=true#<1>
quarkus.micrometer.binder.http-server.enabled=true#<2>
quarkus.micrometer.binder.system=true#<3> 
quarkus.micrometer.export.prometheus.enabled=true#<4>
quarkus.micrometer.export.prometheus.path=/metrics#<5>
quarkus.micrometer.binder.jvm=true#<6>
----
<1> Outbound HTTP request metrics support.
<2> Inbound HTTP request metrics support.
<3> Micrometer System metrics support.
<4> Enable export of metrics to Prometheus.
<5> Customize the path where metrics are exposed.
<6> Micrometer JVM metrics support.

Go to thehttp://localhost:8080/q/swagger-ui/#/Greeting%20Resource/get_messages[Swagger UI] and make several requests.

Now go to http://localhost:8080/metrics[http://localhost:8080/metrics] and search for `http_server_requests_seconds summary`. You will observe that your requests were automatically measured and they also contain the global tags:

[.console-output]
[source, bash]
----
# TYPE http_server_requests_seconds summary
http_server_requests_seconds_count{country="Romania",method="GET",outcome="SUCCESS",profile="dev",region="CEE ",status="200",uri="/messages",} 12.0
http_server_requests_seconds_sum{country="Romania",method="GET",outcome="SUCCESS",profile="dev",region="CEE ",status="200",uri="/messages",} 2.058467696
http_server_requests_seconds_count{country="Romania",method="GET",outcome="SUCCESS",profile="dev",region="CEE ",status="200",uri="/metrics",} 2.0
http_server_requests_seconds_sum{country="Romania",method="GET",outcome="SUCCESS",profile="dev",region="CEE ",status="200",uri="/metrics",} 0.075653411
----

The metrics listed will be exported to Prometheus and further queried over time.
You can also define your own custom metrics, but please keep in mind the Out Of the Box ones as well.
Let's modify `GreetingResource` with the following:

[.console-input]
[source,java]
----
package com.redhat.developers;

import javax.inject.Inject;
import javax.transaction.Transactional;
import javax.ws.rs.GET;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;
import javax.ws.rs.core.Response;

import org.eclipse.microprofile.rest.client.inject.RestClient;
import org.jboss.logging.Logger;
import org.jboss.resteasy.reactive.RestResponse.Status;

import java.util.List;

import io.micrometer.core.annotation.Counted;
import io.micrometer.core.annotation.Timed;

@Path("messages")
public class GreetingResource {

    @Inject
    Logger LOGGER;

    @RestClient
    HelloService helloService;

    public static final String URI = "uri";
    public static final String API_GREET = "api.greet";

    @Path("/init")
    @GET
    @Transactional
    @Produces(MediaType.TEXT_PLAIN)
    public Response init() {
        LOGGER.debug("Updating the db from external service");
        List<Message> messages = Message.findAll().list();
        for (Message message : messages) {
            String language = message.language;
            message.update(helloService.getContent(language).hello, language);
        }
        LOGGER.debug("End update of the db ");

        return Response.status(Status.CREATED).entity("DB initialized").build();

    }

    @POST
    @Transactional
    @Timed(value = "greetings.creation", longTask = true, extraTags = {URI, API_GREET})//<1>
    public Message create(Message message) {
         Message.persist(message);
         return message;
    }

    @GET
    @Path("/sysresources")
    @Produces(MediaType.TEXT_PLAIN)
    public String getSystemResources() {
        long memory = Runtime.getRuntime().maxMemory();
        int cores = Runtime.getRuntime().availableProcessors();
        return " Memory: " + (memory / 1024 / 1024) +
                " Cores: " + cores + "\n";
    }

    @GET
    @Counted(value = "http.get.requests", extraTags = {URI, API_GREET})//<2>
    public List<Message> findAll() {
        return Message.findAll().list();
    }
    

}
----

<1> Measure expected long running requests with `@Timed` annotation.
<2> Count the creation of resources with `@Counted` annotation and your own extra tags.

=== Inspect the custom metrics

Start the application in DevMode:

[.console-input]
[source,bash]
----
mvn quarkus:dev
----

and curl a couple of times the `/messages` endpoint:
[.console-input]
[source,bash]
----
curl localhost:8080/messages
----

You can see your custom metrics recorded at http://localhost:8080/metrics :

[.console-input]
[source,properties]
----
jvm_memory_max_bytes{area="heap",country="Romania",id="Survivor Space",profile="prod",region="CEE",} 4390912.0
jvm_memory_max_bytes{area="heap",country="Romania",id="Eden Space",profile="prod",region="CEE",} 3.5258368E7
jvm_memory_max_bytes{area="heap",country="Romania",id="Tenured Gen",profile="prod",region="CEE",} 8.8080384E7
jvm_memory_max_bytes{area="nonheap",country="Romania",id="CodeHeap 'profiled nmethods'",profile="prod",region="CEE",} 1.22912768E8
jvm_memory_max_bytes{area="nonheap",country="Romania",id="Compressed Class Space",profile="prod",region="CEE",} 1.073741824E9
jvm_memory_max_bytes{area="nonheap",country="Romania",id="Metaspace",profile="prod",region="CEE",} -1.0
jvm_memory_max_bytes{area="nonheap",country="Romania",id="CodeHeap 'non-nmethods'",profile="prod",region="CEE",} 5828608.0
jvm_memory_max_bytes{area="nonheap",country="Romania",id="CodeHeap 'non-profiled nmethods'",profile="prod",region="CEE",} 1.22916864E8
# HELP http_get_requests_total
# TYPE http_get_requests_total counter
http_get_requests_total{class="com.redhat.developers.GreetingResource",country="Romania",exception="none",method="findAll",profile="prod",region="CEE",result="success",uri="api.greet",} 3.0
----

=== Deploy to Kubernetes

You can deploy your latest code changes by using the command:

[.console-input]
[source,bash]
----
mvn clean package -Dquarkus.kubernetes.deploy=true -Dquarkus.container-image.push=true
----

However, we should externalize the configuration to OpenShift resources.
Firstly, let's create a configmap:

[.console-input]
[source,bash]
----
kubectl create cm country-nl --from-literal=REGION=Europe --from-literal=COUNTRY=Netherlands
----

And we can append this new resource to our existing deployment:

[.console-input]
[source,bash]
----
kubectl set env --from=configmap/country-nl deploy/another-greeting-app
----

Rollout the latest `DeploymentConfig` using:
[.console-input]
[source,bash]
----
kubectl rollout restart deploy/another-greeting-app
----

You can now check your overwritten metrics via:

[.console-input]
[source,bash]
----
curl $ROUTE_URL/metrics
----

[#metricsprometheus]
== Inspect metrics in Prometheus

Find the route associated to your application (the one you used in <<Kubernetes Advanced>>) using either the UI or the in-browser terminal:

[.console-input]
[source,bash]
----
export ROUTE_URL=http://$(kubectl get route another-greeting-app -o jsonpath='{.spec.host}')
----

Let's make a few curl requests:

[.console-input]
[source,bash]
----
for i in {1..16}; do curl -v $ROUTE_URL/messages; done
----

When we made the setup of the project, we also exposed the Prometheus installation via a route.
You can find that route using the following command and access Prometheus UI via it:

[.console-input]
[source,bash]
----
export PROMETHEUS_URL=http://$(kubectl get route prometheus -o jsonpath='{.spec.host}')
----

In Prometheus UI enter the following PromQL query to see the average over time of requests to the `/messages` endpoint:

[.console-input]
[source,bash]
----
avg_over_time(http_server_requests_seconds_count{uri="/messages"}[1h])
----

[.mt-4.center]
image::promql_query.png[PromQL query example,600,600,align="center"]

